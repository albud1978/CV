"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –¥–≤–∏–∂–µ–Ω–∏—è –≤ –≤–∏–¥–µ–æ –∏ –Ω–∞—Ä–µ–∑–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç OpenCV Background Subtraction (MOG2) –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è.
–ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –≤–∏–¥–µ–æ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞–º–µ—Ä –Ω–∞–±–ª—é–¥–µ–Ω–∏—è.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python src/utils/motion_detect.py --input input/Video --output output/motion_clips
    
    # –° –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    python src/utils/motion_detect.py --input input/Video --output output/motion_clips --threshold 0.5 --min-duration 2
"""

import os
import sys
import argparse
import cv2
import numpy as np
from pathlib import Path
from tqdm import tqdm
from typing import List, Tuple
from dataclasses import dataclass


@dataclass
class MotionSegment:
    """–°–µ–≥–º–µ–Ω—Ç –≤–∏–¥–µ–æ —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º."""
    start_frame: int
    end_frame: int
    start_time: float
    end_time: float
    avg_motion: float  # –°—Ä–µ–¥–Ω–∏–π % –¥–≤–∏–∂–µ–Ω–∏—è –≤ —Å–µ–≥–º–µ–Ω—Ç–µ


class MotionDetector:
    """
    –î–µ—Ç–µ–∫—Ç–æ—Ä –¥–≤–∏–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Background Subtraction (MOG2).
    """
    
    def __init__(
        self,
        motion_threshold: float = 0.5,
        min_duration: float = 1.0,
        buffer_seconds: float = 1.0,
        history: int = 500,
        var_threshold: int = 16,
        detect_shadows: bool = False
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞.
        
        Args:
            motion_threshold: –ü–æ—Ä–æ–≥ –¥–≤–∏–∂–µ–Ω–∏—è (0-100, % –ø–ª–æ—â–∞–¥–∏ –∫–∞–¥—Ä–∞ —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º)
            min_duration: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ (—Å–µ–∫—É–Ω–¥—ã)
            buffer_seconds: –ë—É—Ñ–µ—Ä –¥–æ/–ø–æ—Å–ª–µ –¥–≤–∏–∂–µ–Ω–∏—è (—Å–µ–∫—É–Ω–¥—ã)
            history: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ñ–æ–Ω–∞
            var_threshold: –ü–æ—Ä–æ–≥ –≤–∞—Ä–∏–∞—Ü–∏–∏ –¥–ª—è MOG2
            detect_shadows: –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–Ω–∏ (–∑–∞–º–µ–¥–ª—è–µ—Ç —Ä–∞–±–æ—Ç—É)
        """
        self.motion_threshold = motion_threshold
        self.min_duration = min_duration
        self.buffer_seconds = buffer_seconds
        self.history = history
        self.var_threshold = var_threshold
        self.detect_shadows = detect_shadows
        
    def analyze_video(self, video_path: str) -> Tuple[List[MotionSegment], dict]:
        """
        –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è.
        
        Args:
            video_path: –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É
            
        Returns:
            Tuple[List[MotionSegment], dict]: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        """
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}")
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤–∏–¥–µ–æ
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        duration = total_frames / fps if fps > 0 else 0
        
        metadata = {
            "fps": fps,
            "total_frames": total_frames,
            "width": width,
            "height": height,
            "duration": duration
        }
        
        # Background Subtractor
        bg_subtractor = cv2.createBackgroundSubtractorMOG2(
            history=self.history,
            varThreshold=self.var_threshold,
            detectShadows=self.detect_shadows
        )
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞–¥—Ä–æ–≤
        motion_frames = []  # (frame_idx, motion_percent)
        
        frame_idx = 0
        pbar = tqdm(total=total_frames, desc="–ê–Ω–∞–ª–∏–∑ –¥–≤–∏–∂–µ–Ω–∏—è", unit="–∫–∞–¥—Ä")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º background subtraction
            fg_mask = bg_subtractor.apply(frame)
            
            # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —à—É–º–∞
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
            fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)
            fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –¥–≤–∏–∂–µ–Ω–∏—è
            motion_pixels = np.count_nonzero(fg_mask)
            total_pixels = fg_mask.shape[0] * fg_mask.shape[1]
            motion_percent = (motion_pixels / total_pixels) * 100
            
            motion_frames.append((frame_idx, motion_percent))
            
            frame_idx += 1
            pbar.update(1)
        
        pbar.close()
        cap.release()
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–µ–≥–º–µ–Ω—Ç—ã —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º
        segments = self._find_motion_segments(motion_frames, fps)
        
        return segments, metadata
    
    def _find_motion_segments(
        self, 
        motion_frames: List[Tuple[int, float]], 
        fps: float
    ) -> List[MotionSegment]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º.
        """
        if not motion_frames:
            return []
        
        segments = []
        in_motion = False
        start_frame = 0
        motion_values = []
        
        buffer_frames = int(self.buffer_seconds * fps)
        min_frames = int(self.min_duration * fps)
        
        for frame_idx, motion_percent in motion_frames:
            if motion_percent >= self.motion_threshold:
                if not in_motion:
                    # –ù–∞—á–∞–ª–æ –¥–≤–∏–∂–µ–Ω–∏—è ‚Äî –ë–ï–ó –±—É—Ñ–µ—Ä–∞ –Ω–∞–∑–∞–¥, —Å—Ä–∞–∑—É —Å –º–æ–º–µ–Ω—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
                    start_frame = frame_idx
                    in_motion = True
                    motion_values = []
                motion_values.append(motion_percent)
            else:
                if in_motion:
                    # –ö–æ–Ω–µ—Ü –¥–≤–∏–∂–µ–Ω–∏—è (—Å –±—É—Ñ–µ—Ä–æ–º –≤–ø–µ—Ä—ë–¥)
                    end_frame = min(len(motion_frames) - 1, frame_idx + buffer_frames)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                    if end_frame - start_frame >= min_frames:
                        segments.append(MotionSegment(
                            start_frame=start_frame,
                            end_frame=end_frame,
                            start_time=start_frame / fps,
                            end_time=end_frame / fps,
                            avg_motion=np.mean(motion_values) if motion_values else 0
                        ))
                    
                    in_motion = False
        
        # –ï—Å–ª–∏ –≤–∏–¥–µ–æ –∑–∞–∫–æ–Ω—á–∏–ª–æ—Å—å –≤–æ –≤—Ä–µ–º—è –¥–≤–∏–∂–µ–Ω–∏—è
        if in_motion:
            end_frame = len(motion_frames) - 1
            if end_frame - start_frame >= min_frames:
                segments.append(MotionSegment(
                    start_frame=start_frame,
                    end_frame=end_frame,
                    start_time=start_frame / fps,
                    end_time=end_frame / fps,
                    avg_motion=np.mean(motion_values) if motion_values else 0
                ))
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –±–ª–∏–∑–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        segments = self._merge_close_segments(segments, fps)
        
        return segments
    
    def _merge_close_segments(
        self, 
        segments: List[MotionSegment], 
        fps: float,
        gap_threshold: float = 30.0  # —Å–µ–∫—É–Ω–¥—ã ‚Äî –æ–±—ä–µ–¥–∏–Ω—è–µ–º –µ—Å–ª–∏ –ø–∞—É–∑–∞ –º–µ–Ω—å—à–µ 30 —Å–µ–∫
    ) -> List[MotionSegment]:
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –±–ª–∏–∑–∫–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã.
        """
        if len(segments) < 2:
            return segments
        
        merged = [segments[0]]
        gap_frames = int(gap_threshold * fps)
        
        for seg in segments[1:]:
            last = merged[-1]
            if seg.start_frame - last.end_frame <= gap_frames:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º
                merged[-1] = MotionSegment(
                    start_frame=last.start_frame,
                    end_frame=seg.end_frame,
                    start_time=last.start_time,
                    end_time=seg.end_time,
                    avg_motion=(last.avg_motion + seg.avg_motion) / 2
                )
            else:
                merged.append(seg)
        
        return merged
    
    def extract_segment(
        self,
        video_path: str,
        segment: MotionSegment,
        output_path: str
    ) -> bool:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç –≤–∏–¥–µ–æ.
        """
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return False
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # –ö–æ–¥–µ–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        cap.set(cv2.CAP_PROP_POS_FRAMES, segment.start_frame)
        
        for _ in range(segment.end_frame - segment.start_frame + 1):
            ret, frame = cap.read()
            if not ret:
                break
            out.write(frame)
        
        cap.release()
        out.release()
        
        return True


def process_videos(
    input_path_str: str,
    output_dir: str,
    motion_threshold: float = 0.5,
    min_duration: float = 1.0,
    buffer_seconds: float = 1.0
):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ –≤–∏–¥–µ–æ –∏–ª–∏ –≤—Å–µ –≤–∏–¥–µ–æ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
    """
    input_path = Path(input_path_str)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
    video_extensions = {'.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm'}
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Ñ–∞–π–ª ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ–≥–æ
    if input_path.is_file():
        if input_path.suffix.lower() in video_extensions:
            video_files = [input_path]
        else:
            print(f"–§–∞–π–ª {input_path} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∏–¥–µ–æ")
            return
    else:
        # –ï—Å–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è ‚Äî –∏—â–µ–º –≤—Å–µ –≤–∏–¥–µ–æ
        video_files = [
            f for f in input_path.iterdir() 
            if f.is_file() and f.suffix.lower() in video_extensions
        ]
    
    if not video_files:
        print(f"–í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {input_path_str}")
        return
    
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(video_files)} –≤–∏–¥–µ–æ")
    print(f"–ü–æ—Ä–æ–≥ –¥–≤–∏–∂–µ–Ω–∏—è: {motion_threshold}%")
    print(f"–ú–∏–Ω. –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {min_duration}—Å")
    print(f"–ë—É—Ñ–µ—Ä: {buffer_seconds}—Å")
    print("-" * 50)
    
    detector = MotionDetector(
        motion_threshold=motion_threshold,
        min_duration=min_duration,
        buffer_seconds=buffer_seconds
    )
    
    total_segments = 0
    
    for video_file in video_files:
        print(f"\nüìπ –û–±—Ä–∞–±–æ—Ç–∫–∞: {video_file.name}")
        
        try:
            segments, metadata = detector.analyze_video(str(video_file))
            
            print(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {metadata['duration']:.1f}—Å")
            print(f"   –ù–∞–π–¥–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º: {len(segments)}")
            
            if not segments:
                print("   ‚ö†Ô∏è  –î–≤–∏–∂–µ–Ω–∏–µ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
                continue
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
            for i, seg in enumerate(segments):
                output_name = f"{video_file.stem}_motion_{i+1:03d}.mp4"
                output_file = output_path / output_name
                
                success = detector.extract_segment(str(video_file), seg, str(output_file))
                
                if success:
                    duration = seg.end_time - seg.start_time
                    print(f"   ‚úÖ {output_name} ({seg.start_time:.1f}s - {seg.end_time:.1f}s, {duration:.1f}s)")
                    total_segments += 1
                else:
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {output_name}")
                    
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
    
    print("\n" + "=" * 50)
    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –ò–∑–≤–ª–µ—á–µ–Ω–æ {total_segments} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="–î–µ—Ç–µ–∫—Ü–∏—è –¥–≤–∏–∂–µ–Ω–∏—è –≤ –≤–∏–¥–µ–æ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤"
    )
    parser.add_argument(
        "--input", "-i",
        type=str,
        default="/app/input/Video",
        help="–ü—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –≤–∏–¥–µ–æ"
    )
    parser.add_argument(
        "--output", "-o",
        type=str,
        default="/app/output/motion_clips",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
    )
    parser.add_argument(
        "--threshold", "-t",
        type=float,
        default=0.5,
        help="–ü–æ—Ä–æ–≥ –¥–≤–∏–∂–µ–Ω–∏—è –≤ %% –ø–ª–æ—â–∞–¥–∏ –∫–∞–¥—Ä–∞ (default: 0.5)"
    )
    parser.add_argument(
        "--min-duration", "-m",
        type=float,
        default=5.0,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (default: 5.0)"
    )
    parser.add_argument(
        "--buffer", "-b",
        type=float,
        default=60.0,
        help="–ë—É—Ñ–µ—Ä –ø–æ—Å–ª–µ –ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (default: 60.0)"
    )
    
    args = parser.parse_args()
    
    process_videos(
        input_dir=args.input,
        output_dir=args.output,
        motion_threshold=args.threshold,
        min_duration=args.min_duration,
        buffer_seconds=args.buffer
    )


if __name__ == "__main__":
    main()

